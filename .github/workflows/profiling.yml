---
name: Performance Profiling

# Run on demand or when performance-related files change
"on":
  workflow_dispatch:
    inputs:
      enable_cpu_profiling:
        description: 'Enable CPU profiling with flamegraph'
        required: false
        type: boolean
        default: true
      enable_allocation_profiling:
        description: 'Enable allocation profiling with DHAT'
        required: false
        type: boolean
        default: true
  push:
    branches:
      - main
      - 'feat/perf-**'
    paths:
      - 'src/monitor/**'
      - 'src/controller/**'
      - 'benches/**'
      - 'docs/performance_plan.md'
  pull_request:
    paths:
      - 'src/monitor/**'
      - 'src/controller/**'
      - 'benches/**'

permissions:
  contents: read

env:
  RUST_BACKTRACE: 1
  # Enable frame pointers for accurate profiling
  RUSTFLAGS: "-C force-frame-pointers=yes"

jobs:
  criterion-benchmarks:
    name: Criterion Benchmarks
    runs-on: windows-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable
          cache: true

      - name: Run benchmarks
        run: |
          # Run all benchmarks including the new process_monitor_bench
          # Note: cargo bench always uses release mode, no --profile flag needed
          # Cargo.toml has bench = false for [lib] to prevent libtest harness conflicts
          cargo bench -- --save-baseline ci-baseline

      - name: Generate benchmark report
        run: |
          echo "# Criterion Benchmark Results" > benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "**Commit:** ${{ github.sha }}" >> benchmark-summary.md
          echo "**Branch:** ${{ github.ref_name }}" >> benchmark-summary.md
          echo "**Date:** $(Get-Date -Format "yyyy-MM-dd HH:mm:ss")" >> benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "See attached artifacts for detailed Criterion reports." >> benchmark-summary.md

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: criterion-benchmarks-${{ github.sha }}
          path: |
            target/criterion/
            benchmark-summary.md
          retention-days: 30
          if-no-files-found: error

      - name: Add benchmark summary to job summary
        run: |
          Get-Content benchmark-summary.md >> $env:GITHUB_STEP_SUMMARY

  cpu-profiling:
    name: CPU Profiling (flamegraph)
    runs-on: windows-latest
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.enable_cpu_profiling == 'true' || github.event_name != 'workflow_dispatch' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable
          cache: true

      - name: Install flamegraph
        run: cargo install flamegraph

      - name: Run CPU profiling with flamegraph
        run: |
          # Create output directory
          New-Item -ItemType Directory -Force -Path profiling-results

          Write-Host "Running CPU profiling with flamegraph..."
          Write-Host "This will exercise poll_processes and handle_process_event for 30 seconds"
          Write-Host ""

          # Generate flamegraph with profiling profile (includes debug symbols)
          # RUSTFLAGS is already set globally with force-frame-pointers
          # The test runs for 30 seconds and exercises the hot paths
          cargo flamegraph --profile profiling --test cpu_profiling_test --output profiling-results/cpu-flamegraph.svg -- --exact --nocapture profile_process_monitoring_hot_paths

          Write-Host ""

          # Verify flamegraph was generated
          if (Test-Path profiling-results/cpu-flamegraph.svg) {
            $size = (Get-Item profiling-results/cpu-flamegraph.svg).Length / 1KB
            Write-Host "✓ Flamegraph generated successfully: $([math]::Round($size, 1)) KB"
            Write-Host ""
            Write-Host "The flamegraph contains symbolicated function names and can be viewed in any browser."
            Write-Host "Look for: easyhdr::monitor::process_monitor::poll_processes (>20% CPU expected)"
          } else {
            Write-Error "Flamegraph generation failed - no output file created"
            exit 1
          }

      - name: Generate profiling report
        run: |
          @"
          # CPU Profiling Results (flamegraph)

          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}

          ## Profile Details

          This flamegraph was generated by running the dedicated CPU profiling test (``tests/cpu_profiling_test.rs``) which exercises the hot paths in process monitoring and event handling for 30 seconds.

          **Test workload:**
          - Process monitor polling at 500ms intervals (aggressive for profiling)
          - Monitors 5 common Windows applications (Chrome, Firefox, OBS, VS Code, Notepad)
          - Exercises both ``poll_processes`` (process enumeration) and ``handle_process_event`` (event handling)

          **Expected to show symbolicated function names** like:
          - ``easyhdr::monitor::process_monitor::poll_processes``
          - ``easyhdr::controller::app_controller::handle_process_event``
          - ``windows::Win32::System::Diagnostics::ToolHelp::CreateToolhelp32Snapshot``

          ## Viewing the Flamegraph

          This artifact contains a self-contained **SVG flamegraph** with full debug symbols from the 30-second CPU profiling test.

          ### How to View

          1. **Download this artifact** and extract ``cpu-flamegraph.svg``
          2. **Open in any web browser** (Chrome, Firefox, Edge, Safari)
          3. **Interact with the flamegraph:**
             - **Click any box** to zoom into that call stack
             - **Click the top box** to reset zoom
             - **Search** using the search box (top right) - try "poll_processes" or "handle_process_event"
             - **Hover over boxes** to see full function names and percentages
             - **Box width = CPU time** - wider boxes consumed more CPU

          ### Color Key

          - **Red/orange colors:** User code (EasyHDR functions)
          - **Yellow colors:** System libraries (Windows APIs)
          - **Green colors:** Kernel functions

          ## What to Look For (Phase 0 Success Criteria)

          **The flamegraph should show actual Rust function names, NOT raw memory addresses!**

          ✅ **Expected hotspots:**
          - ``easyhdr::monitor::process_monitor::poll_processes`` should be **>20% of flamegraph width**
          - ``easyhdr::controller::app_controller::handle_process_event`` should be **>5% visible**
          - ``windows::Win32::System::Diagnostics::ToolHelp::CreateToolhelp32Snapshot`` (Windows API)
          - ``alloc::string::String`` (string allocations)

          ❌ **If you see raw addresses** (like ``0xadd297``, ``0x7ff6abc12345``):
          - Symbolication failed - check that test was built with ``--profile profiling``
          - Verify ``RUSTFLAGS="-C force-frame-pointers=yes"`` was set

          ### Analysis Tips

          - **Windows API calls:** Search for "CreateToolhelp32Snapshot", "Process32FirstW", "Process32NextW"
          - **String allocations:** Search for "String::from" or "alloc::string"
          - **Lock contention:** Search for "parking_lot::Mutex::lock" or "RwLock"
          - **Hot paths:** The widest boxes at the bottom are the most expensive leaf functions

          ## Note on CI Generation

          This flamegraph was generated in CI using ``cargo flamegraph --profile profiling``, which automatically symbolicates function names during generation. No manual conversion or symbol loading required.

          ## Troubleshooting

          If the flamegraph shows raw addresses instead of function names:
          1. Verify the test binary was built with ``--profile profiling`` (includes ``debug = 2``)
          2. Check that ``RUSTFLAGS="-C force-frame-pointers=yes"`` was set during build
          3. Ensure flamegraph has access to PDB files (should be in ``target/profiling/deps/``)

          ## Next Steps

          Use the flamegraph to:
          1. Confirm ``poll_processes`` is the main CPU hotspot (Phase 0 baseline)
          2. Identify allocation-heavy paths (complement with DHAT profiling)
          3. Document baseline metrics in ``docs/performance_plan.md``
          "@ | Out-File -FilePath profiling-results/README.md -Encoding UTF8

      - name: Upload CPU profiling artifacts
        uses: actions/upload-artifact@v4
        with:
          name: cpu-profiling-flamegraph-${{ github.sha }}
          path: profiling-results/
          retention-days: 30
          if-no-files-found: error

  allocation-profiling:
    name: Allocation Profiling (DHAT)
    runs-on: windows-latest
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.enable_allocation_profiling == 'true' || github.event_name != 'workflow_dispatch' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable
          cache: true

      - name: Run allocation profiling
        run: |
          # Run Phase 2.1 profiling test (watch list cloning overhead)
          # See tests/dhat_profiling_test.rs for all available profiling tests
          # This test measures allocation patterns for the watch list cloning optimization
          cargo test --test dhat_profiling_test --release -- profile_watch_list_cloning --nocapture
        continue-on-error: true

      - name: Generate DHAT report
        run: |
          New-Item -ItemType Directory -Force -Path dhat-results

          # Move DHAT output if it exists
          if (Test-Path dhat-heap.json) {
            Move-Item dhat-heap.json dhat-results/
          }

          @"
          # Allocation Profiling Results (DHAT)

          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}

          ## Viewing the Profile

          1. Download the `dhat-heap.json` artifact
          2. Open [DHAT Viewer](https://nnethercote.github.io/dh_view/dh_view.html)
          3. Load `dhat-heap.json` in the viewer

          ## What to Look For (Phase 0 Success Criteria)

          - **Allocation rate:** Baseline should show 200-500 allocations/sec
          - **Hot allocation paths:** Process name extraction, watch list cloning
          - **Memory per poll:** Should measure baseline memory usage per poll cycle
          "@ | Out-File -FilePath dhat-results/README.md -Encoding UTF8

      - name: Upload DHAT profiling artifacts
        uses: actions/upload-artifact@v4
        with:
          name: allocation-profiling-dhat-${{ github.sha }}
          path: dhat-results/
          retention-days: 30
          if-no-files-found: warn

  profiling-summary:
    name: Generate Profiling Summary
    runs-on: ubuntu-latest
    needs: [criterion-benchmarks, cpu-profiling, allocation-profiling]
    if: always()

    steps:
      - name: Generate summary
        run: |
          echo "# Performance Profiling Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Profiling Jobs Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Criterion Benchmarks:** ${{ needs.criterion-benchmarks.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **CPU Profiling (flamegraph):** ${{ needs.cpu-profiling.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Allocation Profiling (DHAT):** ${{ needs.allocation-profiling.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "1. Download profiling artifacts from the workflow run" >> $GITHUB_STEP_SUMMARY
          echo "2. Review Criterion benchmark reports in \`target/criterion/\`" >> $GITHUB_STEP_SUMMARY
          echo "3. View CPU flamegraph (SVG) in any web browser" >> $GITHUB_STEP_SUMMARY
          echo "4. View allocation profile at [DHAT Viewer](https://nnethercote.github.io/dh_view/dh_view.html)" >> $GITHUB_STEP_SUMMARY
          echo "5. Document baseline metrics in \`docs/performance_plan.md\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Phase 0 Success Criteria" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Flamegraph identifies \`poll_processes\` as hotspot (>20% CPU)" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Flamegraph shows \`handle_process_event\` contribution (>5% CPU)" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] DHAT confirms 200-500 allocations/sec baseline" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Criterion baseline captured for regression detection" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Benchmarks run with varying workloads documented" >> $GITHUB_STEP_SUMMARY
