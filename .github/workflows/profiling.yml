---
name: Performance Profiling

# Run on demand or when performance-related files change
"on":
  workflow_dispatch:
    inputs:
      enable_cpu_profiling:
        description: 'Enable CPU profiling with samply'
        required: false
        type: boolean
        default: true
      enable_allocation_profiling:
        description: 'Enable allocation profiling with DHAT'
        required: false
        type: boolean
        default: true
  push:
    branches:
      - main
      - 'feat/perf-**'
    paths:
      - 'src/monitor/**'
      - 'src/controller/**'
      - 'benches/**'
      - 'docs/performance_plan.md'
  pull_request:
    paths:
      - 'src/monitor/**'
      - 'src/controller/**'
      - 'benches/**'

permissions:
  contents: read

env:
  RUST_BACKTRACE: 1
  # Enable frame pointers for accurate profiling
  RUSTFLAGS: "-C force-frame-pointers=yes"

jobs:
  criterion-benchmarks:
    name: Criterion Benchmarks
    runs-on: windows-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable
          cache: true

      - name: Run benchmarks
        run: |
          # Run all benchmarks including the new process_monitor_bench
          # Note: cargo bench always uses release mode, no --profile flag needed
          # Cargo.toml has bench = false for [lib] to prevent libtest harness conflicts
          cargo bench -- --save-baseline ci-baseline

      - name: Generate benchmark report
        run: |
          echo "# Criterion Benchmark Results" > benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "**Commit:** ${{ github.sha }}" >> benchmark-summary.md
          echo "**Branch:** ${{ github.ref_name }}" >> benchmark-summary.md
          echo "**Date:** $(Get-Date -Format "yyyy-MM-dd HH:mm:ss")" >> benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "See attached artifacts for detailed Criterion reports." >> benchmark-summary.md

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: criterion-benchmarks-${{ github.sha }}
          path: |
            target/criterion/
            benchmark-summary.md
          retention-days: 30
          if-no-files-found: error

      - name: Add benchmark summary to job summary
        run: |
          Get-Content benchmark-summary.md >> $env:GITHUB_STEP_SUMMARY

  cpu-profiling:
    name: CPU Profiling (samply)
    runs-on: windows-latest
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.enable_cpu_profiling == 'true' || github.event_name != 'workflow_dispatch' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable
          cache: true

      - name: Install samply
        run: cargo install samply

      - name: Build profiling test binary
        run: |
          # Build test binary with profiling profile (release + debug symbols + frame pointers)
          # The RUSTFLAGS env var is already set globally with force-frame-pointers
          cargo build --profile profiling --tests

      - name: Run CPU profiling
        run: |
          # Create output directory
          New-Item -ItemType Directory -Force -Path profiling-results

          # Find the test binary (it will have a hash in the name)
          $testBinary = Get-ChildItem target/profiling/deps/cpu_profiling_test-*.exe | Select-Object -First 1

          if (!$testBinary) {
            Write-Error "Could not find cpu_profiling_test binary"
            exit 1
          }

          Write-Host "Found test binary: $($testBinary.Name)"
          Write-Host "Running CPU profiling with samply..."
          Write-Host "This will exercise poll_processes and handle_process_event for 30 seconds"

          # Run samply with the profiling test
          # The test runs for 30 seconds and exercises the hot paths
          # Use --save-only to prevent opening browser/web server in CI
          try {
            samply record --save-only -o profiling-results/cpu-profile -- $testBinary.FullName --exact --nocapture profile_process_monitoring_hot_paths
          } catch {
            Write-Host "samply exited (expected - test completed)"
          }

          # Check for generated files (samply creates .etl and .kernel.etl)
          Write-Host "`nLooking for profiling output files..."
          Get-ChildItem profiling-results/ -ErrorAction SilentlyContinue | ForEach-Object {
            Write-Host "  Found: $($_.Name)"
          }

          # Check that ETL file was created
          $etlFiles = @(
            "profiling-results/cpu-profile.etl",
            "profiling-results/cpu-profile.kernel.etl"
          )

          $etlFound = $false
          foreach ($etlFile in $etlFiles) {
            if (Test-Path $etlFile) {
              $etlFound = $true
              $fileSize = (Get-Item $etlFile).Length / 1MB
              Write-Host "Found ETL file: $etlFile ($([math]::Round($fileSize, 2)) MB)"
            }
          }

          if (!$etlFound) {
            Write-Warning "No profiling data generated. This may happen if samply couldn't start."
            Write-Warning "The test should have run for 30 seconds and generated an ETL file."
            exit 1
          }

          Write-Host "`nETL file will be uploaded for manual conversion to JSON"
          Write-Host "The profile should show symbolicated function names (e.g., easyhdr::monitor::process_monitor::poll_processes)"

      - name: Generate profiling report
        run: |
          @"
          # CPU Profiling Results (samply)

          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}

          ## Profile Details

          This profile was generated by running the dedicated CPU profiling test (``tests/cpu_profiling_test.rs``) which exercises the hot paths in process monitoring and event handling for 30 seconds.

          **Test workload:**
          - Process monitor polling at 500ms intervals (aggressive for profiling)
          - Monitors 5 common Windows applications (Chrome, Firefox, OBS, VS Code, Notepad)
          - Exercises both ``poll_processes`` (process enumeration) and ``handle_process_event`` (event handling)

          **Expected to show symbolicated function names** like:
          - ``easyhdr::monitor::process_monitor::poll_processes``
          - ``easyhdr::controller::app_controller::handle_process_event``
          - ``windows::Win32::System::Diagnostics::ToolHelp::CreateToolhelp32Snapshot``

          ## Converting ETL to Firefox Profiler JSON

          This artifact contains a Windows ETL (Event Trace Log) file with **full debug symbols** that needs manual conversion.

          ### Quick Method: Portable Samply (No Installation)

          1. **Download samply portable:**
             - [samply-x86_64-pc-windows-msvc.zip](https://github.com/mstange/samply/releases/download/samply-v0.13.1/samply-x86_64-pc-windows-msvc.zip) (14.2 MB)
             - Extract ``samply.exe`` to any folder

          2. **Download this artifact** and extract the ``.kernel.etl`` file

          3. **Convert to JSON:**
             ``````cmd
             samply.exe import cpu-profile.kernel.etl
             ``````
             Wait for "Processing ETL trace..." to complete and ``profile.json`` to be created, then press **Ctrl+C**

          4. **View in Firefox Profiler:**
             - Open [https://profiler.firefox.com/](https://profiler.firefox.com/)
             - Click "Load a profile from file"
             - Select ``profile.json``

          ### Alternative: Install via Cargo

          If you have Rust installed:
          ``````bash
          cargo install samply
          samply import cpu-profile.kernel.etl
          # Press Ctrl+C after profile.json is created
          ``````

          ### From WSL2 (Linux)

          The ETL file can be accessed from WSL2 at:
          ``````
          /mnt/c/Users/YourUsername/Downloads/cpu-profile.kernel.etl
          ``````

          However, samply requires Windows to process ETL files (they use Windows-specific APIs).

          ## What to Look For (Phase 0 Success Criteria)

          **The profile should show actual Rust function names, NOT raw memory addresses!**

          ✅ **Good profile (symbolicated):**
          - ``easyhdr::monitor::process_monitor::poll_processes`` (>20% CPU)
          - ``easyhdr::controller::app_controller::handle_process_event`` (>5% CPU)
          - ``windows::Win32::System::Diagnostics::ToolHelp::CreateToolhelp32Snapshot``
          - ``std::string::String::from`` (string allocations)

          ❌ **Bad profile (not symbolicated):**
          - ``0xadd297``
          - ``0x7ff6abc12345``
          - Raw memory addresses without function names

          **Additional analysis:**
          - **Windows API calls:** Look for ``CreateToolhelp32Snapshot``, ``Process32FirstW``, ``Process32NextW``
          - **String allocations:** Look for allocation-heavy paths in process name extraction
          - **Lock contention:** Look for ``parking_lot::Mutex::lock`` calls

          ## Why No Automatic Conversion?

          ``samply import`` starts a web server and waits for user input (Ctrl+C), making it incompatible with automated CI environments. Manual conversion takes ~10-30 seconds.

          ## Troubleshooting

          If the profile shows raw addresses instead of function names:
          1. Verify the test binary was built with ``--profile profiling`` (includes ``debug = 2``)
          2. Check that ``RUSTFLAGS="-C force-frame-pointers=yes"`` was set during build
          3. Ensure samply is using the correct PDB files (should be in ``target/profiling/deps/``)
          "@ | Out-File -FilePath profiling-results/README.md -Encoding UTF8

      - name: Upload CPU profiling artifacts
        uses: actions/upload-artifact@v4
        with:
          name: cpu-profiling-samply-${{ github.sha }}
          path: profiling-results/
          retention-days: 30
          if-no-files-found: warn

  allocation-profiling:
    name: Allocation Profiling (DHAT)
    runs-on: windows-latest
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.enable_allocation_profiling == 'true' || github.event_name != 'workflow_dispatch' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable
          cache: true

      - name: Run allocation profiling
        run: |
          # Run Phase 2.1 profiling test (watch list cloning overhead)
          # See tests/dhat_profiling_test.rs for all available profiling tests
          # This test measures allocation patterns for the watch list cloning optimization
          cargo test --test dhat_profiling_test --release -- profile_watch_list_cloning --nocapture
        continue-on-error: true

      - name: Generate DHAT report
        run: |
          New-Item -ItemType Directory -Force -Path dhat-results

          # Move DHAT output if it exists
          if (Test-Path dhat-heap.json) {
            Move-Item dhat-heap.json dhat-results/
          }

          @"
          # Allocation Profiling Results (DHAT)

          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}

          ## Viewing the Profile

          1. Download the `dhat-heap.json` artifact
          2. Open [DHAT Viewer](https://nnethercote.github.io/dh_view/dh_view.html)
          3. Load `dhat-heap.json` in the viewer

          ## What to Look For (Phase 0 Success Criteria)

          - **Allocation rate:** Baseline should show 200-500 allocations/sec
          - **Hot allocation paths:** Process name extraction, watch list cloning
          - **Memory per poll:** Should measure baseline memory usage per poll cycle
          "@ | Out-File -FilePath dhat-results/README.md -Encoding UTF8

      - name: Upload DHAT profiling artifacts
        uses: actions/upload-artifact@v4
        with:
          name: allocation-profiling-dhat-${{ github.sha }}
          path: dhat-results/
          retention-days: 30
          if-no-files-found: warn

  profiling-summary:
    name: Generate Profiling Summary
    runs-on: ubuntu-latest
    needs: [criterion-benchmarks, cpu-profiling, allocation-profiling]
    if: always()

    steps:
      - name: Generate summary
        run: |
          echo "# Performance Profiling Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Profiling Jobs Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Criterion Benchmarks:** ${{ needs.criterion-benchmarks.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **CPU Profiling (samply):** ${{ needs.cpu-profiling.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Allocation Profiling (DHAT):** ${{ needs.allocation-profiling.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "1. Download profiling artifacts from the workflow run" >> $GITHUB_STEP_SUMMARY
          echo "2. Review Criterion benchmark reports in \`target/criterion/\`" >> $GITHUB_STEP_SUMMARY
          echo "3. View CPU profile at [Firefox Profiler](https://profiler.firefox.com/)" >> $GITHUB_STEP_SUMMARY
          echo "4. View allocation profile at [DHAT Viewer](https://nnethercote.github.io/dh_view/dh_view.html)" >> $GITHUB_STEP_SUMMARY
          echo "5. Document baseline metrics in \`docs/performance_plan.md\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Phase 0 Success Criteria" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Flamegraph identifies \`poll_processes\` as hotspot (>20% CPU)" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Flamegraph shows \`handle_process_event\` contribution (>5% CPU)" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] DHAT confirms 200-500 allocations/sec baseline" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Criterion baseline captured for regression detection" >> $GITHUB_STEP_SUMMARY
          echo "- [ ] Benchmarks run with varying workloads documented" >> $GITHUB_STEP_SUMMARY
